<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Statistical Methods for  High Dimensional Biology STAT/BIOF/GSAT 540</title>
    <meta charset="utf-8" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Statistical Methods for <br>High Dimensional Biology<br><font size=8>STAT/BIOF/GSAT 540</font>
## <font color=red> Lecture 5 – Two Group Comparisons </font> <br style=line-height:2><br> Instructor name
### <font size=5> Slides by: Gabriela Cohen Freue with contributions from Jenny Bryan and Sara Mostafavi</font>

---

class: middle

![Picture from Dr. Fowler, UW](L5_TwoGroupComp_files/statInference.png)
We want to understand a **population** (e.g., gene behaviour) but we can only study a &lt;font color=red&gt;**random sample**&lt;/font&gt; from it. *[Picture from Dr. Fowler, UW]*
---
class: middle
# Book and online resources
* Linear Models with R by Julian Faraway, Chapman &amp; Hall/CRC Texts in Statistical Science, 2004

* http://www.biostat.jhsph.edu/~iruczins/teaching/jf/faraway.html

* https://sites.google.com/a/cs.washington.edu/genome560-spr18/CourseMaterials

* http://genomicsclass.github.io/book/

---
class: middle
# &lt;center&gt; Hypothesis Testing in Genomics
![](L5_TwoGroupComp_files/paperRef.PNG)

&lt;big&gt;

&lt;img width="300" style="padding:0 px; float:right" src="L5_TwoGroupComp_files/cellTypes.png"&gt;
- Retina presents a model system for investigating **regulatory networks** underlying neuronal differentiation.

- **Nrl** transcription factor is known to be important for Rod development

- &lt;font color="red"&gt;**What happens if you delete Nrl?**

---
class: middle

# &lt;center&gt; Why a Hypothesis Test?
&lt;big&gt;
From paper: *". we hypothesized that Nrl is the ideal transcription factor to gain insights into gene expression changes ..."*

&gt; **Biological question:** Is the expression level of gene A affected by ablation of the Nrl gene?

### We can use &lt;font color=red&gt;statistical inference&lt;/font&gt; to answer this biological question!

**Statistical inference**: we observe and study a &lt;font color=red&gt;random sample&lt;/font&gt; to make conclusions about a population (e.g., random sample of gene expressions from mice)

&lt;img width="350" style="padding:0 px; float:right" src="L5_TwoGroupComp_files/NrlKOmouse.png"&gt;
**Experimental design**:
&lt;br&gt; 4 developmental stages
&lt;br&gt; 2 genotypes: Wild type, NrlKO
&lt;br&gt; 3-4 replicas for each combination


---
&lt;big&gt;
Let's take a look at 2 genes as an example: **Irs4 and Nrl**

&gt; **Biological question**: Are these genes truly different in NrlKO compared to WT?

We can't answer this question in general. We can *only* study these genes in collected data.

### &lt;center&gt;&lt;font color="red"&gt; We only observe a random sample of gene expressions.&lt;/font&gt;



![](L5_TwoGroupComp_files/figure-html/unnamed-chunk-2-1.svg)&lt;!-- --&gt;

---
class: middle

# &lt;center&gt; Statistical Hypothesis
&lt;big&gt;
** Experimental design:**
  - 2 conditions: Wt *vs* NrlKO
  - random sample: we observe the expression of many genes in all mice

** Biological hypothesis:** for some  genes, the expression levels are different in both conditions.

** Statistical hypotheses:** (for each gene ...)
  - H&lt;sub&gt;0&lt;/sub&gt; (null hypothesis): the expression level of gene A is the same in both conditions.
  - &lt;font color="blue"&gt;H&lt;sub&gt;A&lt;/sub&gt; (alternative hypothesis): the expression level of gene A is different.&lt;/font&gt;
---
class: middle

## Notation

&lt;big&gt;

### Random variables and estimates (we can observe)

`\(Y_i\)` : expression of gene A in the WT sample `\(i\)`

`\(Z_i\)`: expression of gene A in NrlKO sample `\(i\)`

`\(Y_1, Y_2,..., Y_{n_Y}\)` : a &lt;font color="red"&gt;random sample&lt;/font&gt; of size `\(n_Y\)`

`\(\bar{Y}=\frac{\sum_{i=1}^{n_Y}Y_i}{n_Y}\)`: sample mean of gene A expressions from WT mice

### Population parameters (unknown)

`\(\mu_Y = E[Y]\)` : the (population) expected expression of gene A in WT mice
&gt; &lt;small&gt; note the different meanings of the word "sample"
---

&lt;big&gt;

### &lt;font color="red"&gt;  Is there **enough** evidence in the data to reject H&lt;sub&gt;0&lt;/sub&gt;? &lt;/font&gt;

&gt; H&lt;sub&gt;0&lt;/sub&gt;: `\(\mu_Y = \mu_Z\)`

![](L5_TwoGroupComp_files/figure-html/unnamed-chunk-3-1.svg)&lt;!-- --&gt;

### **Statistical Inference**: random samples are used to learn about the population 
---
class: middle

### We observe... the difference between the **sample averages**: `\(\bar{Y}\)` vs `\(\bar{Z}\)`
![](L5_TwoGroupComp_files/figure-html/unnamed-chunk-4-1.svg)&lt;!-- --&gt;


```r
theAvgs &lt;- with(miniDat,
                 tapply(gExp, list(gType, gene), mean))
```


```
##        Irs4    Nrl
## wt    7.766 11.244
## NrlKO 7.740  6.090
```


```r
theDiff &lt;- theAvgs["NrlKO", ] - theAvgs["wt", ]
```

```
##   Irs4    Nrl 
## -0.026 -5.155
```

---
class: middle

### Is the difference between `\(\bar{Y}\)` and `\(\bar{Z}\)` informative to reject H&lt;sub&gt;0&lt;/sub&gt;?

![](L5_TwoGroupComp_files/figure-html/unnamed-chunk-9-1.svg)&lt;!-- --&gt;

&lt;big&gt;
- The sample means, `\(\bar{Y}\)` vs `\(\bar{Z}\)`, by themselves are not enough to make conclusions about the population

- What is a "large" difference? "large" relative to what?
---
class: center, middle


![](L5_TwoGroupComp_files/figure-html/unnamed-chunk-10-1.svg)&lt;!-- --&gt;


.pull-left[
### What can we use to interpret the size of the mean difference?
]
.pull-right[
### `$$\frac{\bar{Y}-\bar{Z}}{??}$$`
]
---
class: center, middle
### What can we use to interpret the size of the mean difference?

.pull-left[
### "large" relative to the observed variation
]
.pull-right[
### `\(\frac{\bar{Y}-\bar{Z}}{\sqrt{V(\bar{Y}-\bar{Z})}}\)`
]

![](L5_TwoGroupComp_files/figure-html/unnamed-chunk-11-1.svg)&lt;!-- --&gt;
---
class: middle

### Assuming that the random variables of each group are independent and identically distributed (iid):
- `\(Y_1, Y_2,..., Y_{n_Y}\)` are iid
- `\(Z_1, Z_2,..., Z_{n_Z}\)` are iid
- `\(Y_i, Z_j\)` are independent

`$$V(\bar{Z}-\bar{Y})=\frac{\sigma_Z^2}{n_Z}+\frac{\sigma_Y^2}{n_Y}$$`
&lt;br&gt;
If we also assume equal population variances:&lt;/big&gt; `\(\sigma_Z^2=\sigma_Y^2=\sigma^2\)`
`$$V(\bar{Z}-\bar{Y})=\frac{\sigma_Z^2}{n_Z}+\frac{\sigma_Y^2}{n_Y}=\sigma^2\left[\frac{1}{n_Z}+\frac{1}{n_Y}\right]$$`
### But how can we calculate population variance `\(\sigma\)` if it is **unknown**?
---
class: middle

### ...using the sample variances (combined, somehow)!
![](L5_TwoGroupComp_files/figure-html/unnamed-chunk-12-1.svg)&lt;!-- --&gt;


```r
theVars &lt;- with(miniDat,
                 tapply(gExp, list(gType, gene), var))
```
.pull-left[


```
##        Irs4   Nrl
## wt    0.024 1.224
## NrlKO 0.023 0.594
```
]
.pull-right[
&lt;small&gt; `$$\text{e.g., for Nrl: } S_Y^2=\frac{1}{n_Y}\sum_{i=1}^{n_Y}(Y_i-\bar{Y})^2=1.224$$`
]
---
class: middle

### Plug these sample variances into your chosen formula for the variance of the difference of sample means


Assuming &lt;b&gt;equal&lt;/b&gt; variance of Y's and Z's

`$$'pooled'\;\hat{\sigma}^2=S_Y^2\frac{n_Y-1}{n_Y+n_Z-2}+S_Z^2\frac{n_z-1}{n_Y+n_Z-2}$$`
`$$\hat{V}(\bar{Z_n}-\bar{Y_n})=\;'pooled'\;\hat{\sigma}^2\left[\frac{1}{n_Y}+\frac{1}{n_Z}\right]$$`
&lt;br&gt;
Assuming &lt;b&gt;unequal&lt;/b&gt; variance of Y's and Z's
`$$\hat{V}(\bar{Z_n}-\bar{Y_n})=\hat{\sigma}_{\bar{Z}_n-\bar{Y}_n}^2=\frac{S_Y^2}{n_Y}+\frac{S_Z^2}{n_Z}$$`

&gt; Note: the 'hat' (^) is used to distinguish an 'estimate' from a 'parameter'.

---
class: middle




## &lt;center&gt; The Test Statistic:  &lt;small&gt; `\(T=\frac{\bar{Z}_n-\bar{Y}_n}{\hat{\sigma}_{Z_n-Y_n}}\)`&lt;/small&gt;

Assuming equal variances:

```r
tstStat &lt;- theDiff / sqrt(s2Diff)
```

```
##    Irs4     Nrl 
##  -0.529 -16.795
```
Without assuming equal variances:

```r
welchStat &lt;- theDiff / sqrt(s2DiffWelch)
```

```
##    Irs4     Nrl 
##  -0.529 -16.949
```
### Can we now say that the observed differences are 'big'?

The difference is about half a standard deviation for Irs4 and ~16 standard deviations for Nrl. 

---
class: middle

### The test statistic T is a &lt;font color=red&gt;random variable&lt;/font&gt; because it's based on our &lt;font color=red&gt;random sample&lt;/font&gt;.

### We need a measure of its uncertainty to determine how big T is:
&gt; ### If we were to repeat the experiment many times, what's the probability of observing a value of T **as extreme** as the one we observed?

### We need to have a probability distribution!
### However, this is unknown to us so we need to **make more assumptions**.
---
class: middle

### Theory now tells us specific **null distributions** for these test statistics, depending on your assumptions.

### --&gt;  Willing to assume that F and G are normal distributions?

.pull-left[
### &lt;center&gt; 2-sample *t*-test: 
 &lt;center&gt; (equal variances)
`$$T\sim t_{n_Y+n_Z-2}$$`
]
.pull-right[
### &lt;center&gt; Welch test:
&lt;center&gt; (unequal variances)
`$$T\sim t_{&lt;something\,ugly&gt;}$$`
]

### --&gt; Unwilling to assume that F and G are normal distributions? But you feel that n&lt;sub&gt;Y&lt;/sub&gt; and n&lt;sub&gt;Z&lt;/sub&gt; are large enough?

Then the t-distributions above or even a normal distribution are decent approximations.

---
class: middle

## Student's *t*-distribution
### Recall that T is a **random variable**. Under certain assumptions, we can prove that T follows a *t*-distribution.

&lt;center&gt;&lt;img src="L5_TwoGroupComp_files/stuTDist.png" width="400"&gt;

where df = degrees of freedom.
---
class: middle
# &lt;center&gt; Hypothesis testing

### 1. Define a **test statistic**: 2-sample *t*-test
### 2. Compute the &lt;font color=red&gt;observed value&lt;/font&gt; for the test statistic


```r
tstStat &lt;- theDiff / sqrt(s2Diff)
```

```
##    Irs4     Nrl 
##  -0.529 -16.795
```

---
class: middle
### 3. Compute the probability of seeing a test statistic as extreme as that observed, under the **null sampling distribution** (p-value) 



```
## miniDat$gene: Irs4
## [1] 0.6002058
## -------------------------------------------------------- 
## miniDat$gene: Nrl
## [1] 6.764663e-19
```

.pull-left[
### Assuming that H&lt;sub&gt;0&lt;/sub&gt; is true: 
for Irs4, the probability of seeing a test statistic as extreme that observed (*t* = -0.53) is pretty high (*p*=0.6).
]
.pull-right[
&lt;img src="L5_TwoGroupComp_files/nDist.png" width=400 &gt;
]

---
class: middle

### 4. Make a decision about significance of results, based on a pre-specified value (alpha, significance level)


The significance level `\(\alpha\)` is usually set at 0.05. However, this value is arbitrary and usually depends on the study.

Using `\(\alpha=0.05\)`, since the p-value for the Irs4 test is greater than 0.05, we conclude that there is not &lt;font color=red&gt;*enough*&amp;nbsp; evidence &lt;/font&gt; in the data to claim that Irs4 has a differential expression in WT compared to Nrl models. 

We do not reject H&lt;sub&gt;0&lt;/sub&gt;!

---
class: center

![](L5_TwoGroupComp_files/slide23.png)
---
class: middle

## What is a p-value?

&gt; Likelihood of obtaining a test statistic at least &lt;font color=green&gt; as extreme as the one observed&lt;/font&gt;, given that the null hypothesis is true (we are making a conditional p-value statement)

## What is a p-value &lt;font color=red&gt;NOT&lt;/font&gt;?

- Not the probability that the &lt;font color=red&gt;null hypothesis is true&lt;/font&gt;

- Not the probability that the &lt;font color=red&gt;finding is a “fluke”&lt;/font&gt;

- Not the probability of &lt;font color=red&gt;falsely rejecting the null&lt;/font&gt;

- Does not &lt;font color=red&gt;indicate the size or importance&lt;/font&gt; of observed effects. 

*[Credit to Dr. Fowler, UW]*
---
&lt;big&gt;
## "Genome-wide" testing of differential expression
- In genomics, we often perform thousands of statistical tests (e.g., a *t*-test per gene)

- The distribution of p-values across all tests provide good diagnostics/insights.

- Is it uniform (should be in most experiments) and if not, is the departure from uniform expected based on biological knowledge?

--
### Different kinds of *t*-tests:
- One sample *or* **two samples**
- One-sided *or* **two sided**
- Paired *or* **unpaired**
- **Equal variance** *or* unequal variance

---
class: middle

# Types of Errors in Hypothesis Testing

&lt;center&gt;![](L5_TwoGroupComp_files/hypError.png)
*[Picture from Dr. Fowler, UW]*
---
class: middle

&lt;big&gt;
What if you don't wish to assume the underlying data is normally distributed AND you aren't sure your samples are large enough to invoke CLT?
&lt;/big&gt;
## What are alternatives to the *t*-test?

&lt;big&gt;
First, one could use the t test statistic but use a **bootstrap approach** to compute its p-value. We will cover this later on.

Alternatively, there are *non-parametric* tests that are available here:

- **Wilcoxon rank sum test**, aka Mann Whitney, uses ranks to test differences in population means.

- **Kolmogorov-Smirnov test** uses the empirical CDF to test differences in population cumulative distributions.

---
class: middle

# Wilcoxon rank sum test

&lt;big&gt;
Rank all data, ignoring the **grouping** variable

**Test statistic** = sum of the ranks for one group (optionally, subtract the minimum possible which is `\(\frac{n_Y(n_Y+1)}{2}\)`)

(Alternative but equivalent formulation based on the number of `\(y_i, z_i\)` pairs for which `\(y_i \geq z_i\)`)

Null distribution of such statistics can be worked out or approximated.

---
class: middle, center
![](L5_TwoGroupComp_files/slide32.png)

![](L5_TwoGroupComp_files/figure-html/unnamed-chunk-23-1.svg)&lt;!-- --&gt;
---
class: middle

# Kolmogorov-Smirnov test (two sample)

&lt;big&gt;

**Null hypothesis**: F = G, i.e. the distributions are the same

Estimate each CDF with the empirical CDF (ECDF)

`$$\hat{F}(x)=\frac{1}{n}\sum_{i=1}^n{I[x_i\leq{x}]}$$`

**Test statistic** is the maximum of the absolute difference between the ECDFs

`$$max|\hat{F}(x)-\hat{G}(x)|$$`

Null distribution does not depend on F, G (!)
&lt;br&gt;(I'm suppressing a detail here.)

---

![](L5_TwoGroupComp_files/slide34.png)

---
class: middle

# Discussion and questions ...
&lt;big&gt;

What if you are unsure whether your sample size is large enough? Outliers with small samples could be problematic

Which test result should one report ... the 2-sample *t*-test, the Wilcoxon, or the KS?

Treat p-values as one type of evidence that you should incorporate with others. 

It is worrisome when methods that are equally appropriate and defensible give very different answers.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
